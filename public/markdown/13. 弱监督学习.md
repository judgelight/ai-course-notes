---
marp: true
theme: default
paginate: true
math: katex
---

<style>
section {
  font-family: "Microsoft YaHei", "PingFang SC", "Source Han Sans", "Noto Sans CJK SC", sans-serif;
}
</style>

# <!-- fit -->📘 第13讲：弱监督学习

---

## 1. 概念与定义

**弱监督学习（Weakly Supervised Learning, WSL）**

是一类在训练中使用**不完全、不精确或不准确标签**的数据进行建模的机器学习方法。
它介于**全监督**（完全准确标签）与**无监督**（无标签）之间，旨在最大化利用廉价获取的大规模数据，即使这些数据的监督信号存在缺陷。

---

## 2. 三大类型

1. **不完全监督（Incomplete Supervision）**

   * 只有一小部分样本有人工高质量标签，其余无标签。
   * 例：100 万张图片中，只有 5 万张人工标注。

2. **不精确监督（Inexact Supervision）**

   * 标签粒度不够细，无法直接满足训练任务的精确需求。
   * 例：只有图像的整体类别标签，而任务是目标检测（需要目标位置）。

3. **不准确监督（Inaccurate Supervision）**

   * 标签存在噪声或错误。
   * 例：从网络爬取的图片标签错误率较高。

---

## 3. 常见应用场景

* **医学影像**：有限的精确标注，大量粗粒度诊断标签。
* **搜索推荐**：用户点击、停留时间作为弱标签（但并不等于真实兴趣）。
* **自动抓取网页数据**：爬虫+关键词匹配生成标签，精确度不高。
* **远程监督（Distant Supervision）**：通过外部知识库对数据自动打标签。

---

## 4. 一般实现流程

### Step 1：数据获取

* 来源：网络爬虫、日志行为、知识库映射、半自动标注工具。
* 保留一部分人工高质量标签作为验证集。

### Step 2：数据清洗与质量评估

* **规则过滤**：去掉明显错误数据。
* **Baseline 模型筛选**：初步过滤低置信度样本。
* **噪声率估计**：用小规模人工标签评估弱标签准确率。

---

### Step 3：标签增强与修正

* **伪标签（Pseudo-labeling）**：用初始模型预测无标签数据并选取高置信样本。
* **标签平滑（Label Smoothing）**：减少错误标签的影响。
* **多源融合**：加权投票、贝叶斯合并多个标签来源。

### Step 4：训练策略

* **噪声鲁棒损失函数**：MAE、Bootstrap Loss、Focal Loss。
* **半监督结合**：MixMatch、FixMatch、Mean Teacher。
* **多任务学习**：用附加弱标签信息作为辅助任务。

---

### Step 5：模型评估

* 使用高质量验证集。
* 评估指标依任务而定：Accuracy/F1/mAP/ROC-AUC 等。

### Step 6：部署与迭代

* 上线后持续收集新数据。
* 增量学习（Incremental Learning）。
* 主动学习（Active Learning）标注不确定样本。

---

## 5. 常用方法与技术

| 任务问题  | 方法示例                                        | 核心思想             |
| ----- | ------------------------------------------- | ---------------- |
| 噪声标签  | Bootstrap Loss, Co-teaching                 | 减少错误标签的负面影响      |
| 粗粒度标签 | Multiple Instance Learning (MIL)            | 通过包（bag）标签推断实例标签 |
| 部分标注  | Pseudo-labeling, Consistency Regularization | 利用无标签数据生成标签      |
| 标签融合  | Majority Voting, Bayesian Label Fusion      | 多来源标签合并提升精度      |

---


## 6. Bootstrap Loss 详解

**1）公式定义**
在二分类中，Bootstrap Loss 会把当前的**弱标签**（可能有错）与模型自己的预测结果融合成一个**软标签**：

$$
y_\text{soft} = \beta \cdot y_\text{noisy} + (1 - \beta) \cdot p_\text{detach}
$$

* $y_\text{noisy}$：弱标签（可能有噪声）
* $p_\text{detach}$：模型当前预测（梯度不回传）
* $\beta \in [0,1]$：融合权重

最终用 **BCE 损失** 计算：

$$
\mathcal{L} = \text{BCE}(p, y_\text{soft})
$$

---

**2）它如何降低错误标签的主导权？**

* 在普通交叉熵中，弱标签是唯一的训练信号，一旦它是错的，就会强制模型学错。
* Bootstrap Loss 用 $(1-\beta)$ 部分权重替换成模型自己的预测，等于**减少了错误标签对损失的影响**。
* 对正确标签样本，模型预测和标签一致，融合结果依然接近正确值；
* 对错误标签样本，模型预测往往与标签差异较大，融合后会被“拉回”更合理的位置，从而降低梯度方向的误导程度。

---

**3）适用场景**

* 标签噪声随机且不可完全去除（如网络爬取、用户行为日志）。
* 可以提前训练出一个较稳定的模型，使预测值在多数样本上可信度高。

---

**4）超参数 $\beta$ 的影响**

* $\beta \to 1$：更依赖标签（鲁棒性弱）
* $\beta \to 0$：更依赖预测（可能导致模型自我强化错误模式）
* 常用取值：0.6 – 0.9，需通过验证集调优。


---

## 7. 弱监督学习 vs 半监督学习

| 维度     | 弱监督学习（WSL）        | 半监督学习（SSL）           |
| ------ | ----------------- | -------------------- |
| 标签问题来源 | 标签可能缺失、粗粒度、或含噪    | 主要是缺失标签（部分数据无标签）     |
| 数据质量   | 低质量标签普遍存在         | 已标注部分通常高质量           |
| 典型方法   | 噪声鲁棒损失、标签修正、多实例学习 | 一致性正则化、伪标签、自训练       |
| 关注重点   | 如何利用不完美标签         | 如何利用无标签数据            |
| 场景     | 爬虫数据、远程监督、弱标注检测   | 课堂作业评分、小部分精确标注大部分无标签 |
| 难点     | 处理标签噪声、模糊标签粒度     | 防止伪标签误导模型            |

---

> **总结**：半监督学习是弱监督学习的一个子集（不完全监督的一种），而弱监督学习的范围更广，处理的标签问题更多样。

---

## 8. 应用案例

1. **图像分类（噪声标签）**

   * 从网络爬取猫狗图片 → 人工标注 5% 样本 → 噪声鲁棒训练。
2. **医学影像（粗粒度标签）**

   * 只知道患者是否患病（图像整体标签） → 目标是定位病灶。
3. **搜索排序（行为日志）**

   * 点击/停留时间作为弱标签，训练 CTR 预测模型。

---

## 9. 核心要点总结

* 弱监督学习能让模型在**便宜但不完美的数据**上训练。
* 三类问题：**标签缺失**、**粒度不精确**、**标签有噪声**。
* 实现关键：

  1. 数据清洗与质量评估
  2. 标签增强（伪标签、平滑、多源融合）
  3. 噪声鲁棒训练策略
* 半监督学习是弱监督学习的一种特殊情况（处理的是无标签问题）。
* 与主动学习、半监督结合能进一步提升性能。

---

# <!-- fit -->📘  实战演示

用一个猫狗图片分类的案例，来做一个弱监督学习的完整演示。
我们假设数据是从互联网上爬取的，所以标签存在一定比例的错误，这就是典型的**不准确监督（Inaccurate Supervision）**场景。

---

## 1. 数据准备：模拟弱标签

我们用 `torchvision.datasets.CIFAR10` 来替代猫狗数据，并只取**cat** 和 **dog** 两类。
然后人为制造标签噪声（20% 随机反转标签）。

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np

# 转换（缩放+张量化）
transform = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor()
])

# 加载 CIFAR-10
trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)

# 只保留猫(3)和狗(5)
def filter_cats_dogs(dataset):
    imgs, labels = [], []
    for img, label in dataset:
        if label in [3,5]:  # 3=cat, 5=dog
            imgs.append(img)
            labels.append(0 if label==3 else 1)  # cat=0, dog=1
    return torch.stack(imgs), torch.tensor(labels)

X_train, y_train = filter_cats_dogs(trainset)
X_test, y_test = filter_cats_dogs(testset)

# 制造20%噪声标签
noise_rate = 0.2
num_noisy = int(len(y_train) * noise_rate)
noise_idx = np.random.choice(len(y_train), num_noisy, replace=False)
y_train_noisy = y_train.clone()
y_train_noisy[noise_idx] = 1 - y_train_noisy[noise_idx]  # 标签反转

print(f"训练样本: {len(X_train)}, 含噪声样本: {num_noisy}")
```

---

## 2. 数据清洗与分析

在真实项目中，这一步可能包括：

* 用简单模型或启发式规则筛掉明显错标的样本
* 用人工标注小部分数据评估标签准确率

在这个演示里，我们直接带着噪声进入训练（重点在于鲁棒方法）。

---

## 3. 弱监督训练：噪声鲁棒损失

这里我们使用 **Bootstrap Loss**（结合标签和模型预测的软标签），这样错误标签对模型的影响会降低。

```python
from torch.utils.data import DataLoader, TensorDataset

# DataLoader
train_loader = DataLoader(TensorDataset(X_train, y_train_noisy.float()), batch_size=64, shuffle=True)
test_loader = DataLoader(TensorDataset(X_test, y_test.float()), batch_size=64)

# 简单CNN
class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64*16*16, 128), nn.ReLU(),
            nn.Linear(128, 1), nn.Sigmoid()
        )
    def forward(self, x):
        return self.classifier(self.features(x))

# Bootstrap Loss
class BootstrapLoss(nn.Module):
    def __init__(self, beta=0.8):
        super().__init__()
        self.beta = beta
        self.bce = nn.BCELoss()

    def forward(self, preds, labels):
        soft_labels = self.beta * labels + (1 - self.beta) * preds.detach()
        return self.bce(preds, soft_labels)

# 训练
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleCNN().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = BootstrapLoss(beta=0.8)

for epoch in range(5):
    model.train()
    total_loss = 0
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        preds = model(X_batch).squeeze()
        loss = criterion(preds, y_batch)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}")
```

---

## 4. 模型评估

```python
model.eval()
correct, total = 0, 0
with torch.no_grad():
    for X_batch, y_batch in test_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        preds = (model(X_batch).squeeze() > 0.5).float()
        correct += (preds == y_batch).sum().item()
        total += y_batch.size(0)
print(f"Test Accuracy: {correct/total:.4f}")
```

---

## 5. 改进思路

在真实弱监督项目中，你可以进一步优化：

1. **标签平滑（Label Smoothing）** → 降低硬标签对模型的约束。
2. **多模型协同（Co-teaching）** → 两个模型互相筛选对方的干净样本。
3. **半监督结合** → 对高置信度样本生成伪标签训练。

