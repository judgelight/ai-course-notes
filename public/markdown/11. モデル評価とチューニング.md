---
marp: true
theme: default
paginate: true
math: katex
---

<style>
section {
  font-family: "Microsoft YaHei", "PingFang SC", "Source Han Sans", "Noto Sans CJK SC", sans-serif;
}
</style>


# <!-- fit -->📘 第11講：モデル評価とチューニング

---

## 一、分類タスクの評価指標

### 1. 混同行列（Confusion Matrix）

二値分類問題において、正クラスを「1」、負クラスを「0」とすると、モデルの予測と実際のラベルの組み合わせは次の４つに分類され、混同行列を構成します。

![bg right:50% 90%](https://s.ar8.top/img/picgo/20250716164746646.webp)

---

|               | 予測：正クラス (1) | 予測：負クラス (0) |
| ------------- | ------------------ | ------------------ |
| **実際：正クラス (1)** | 真陽性 (TP)         | 偽陰性 (FN)         |
| **実際：負クラス (0)** | 偽陽性 (FP)         | 真陰性 (TN)         |

* **TP (True Positive／真陽性)**：正クラスを正クラスと予測  
* **TN (True Negative／真陰性)**：負クラスを負クラスと予測  
* **FP (False Positive／偽陽性)**：負クラスを誤って正クラスと予測  
* **FN (False Negative／偽陰性)**：正クラスを誤って負クラスと予測  



---

### 2. 正解率（Accuracy）

全体の予測のうち、正しく予測された割合を示します：

$$
\mathrm{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

* 長所：直観的で分かりやすい  
* 短所：クラス分布が大きく偏っている場合（例：正負サンプル比が1:100など）、Accuracyは誤解を招きやすい  

---

### 3. 適合率（Precision）と再現率（Recall）

* **適合率（Precision）**：予測を正クラスとしたサンプルのうち、実際に正クラスである割合。

  $$
    \mathrm{Precision} = \frac{TP}{TP + FP}
  $$
* **再現率（Recall）**（感度／Sensitivity／TPRとも呼ぶ）：実際の正クラスサンプルのうち、正しく正クラスと予測された割合。

  $$
    \mathrm{Recall} = \frac{TP}{TP + FN}
  $$

| 指標          | 重視する点           | 適用例                     |
| ------------- | -------------------- | -------------------------- |
| Precision     | 偽陽性（FP）を減らす | ウイルス検査、スパムフィルタ |
| Recall        | 偽陰性（FN）を減らす | 疾病スクリーニング、安全監視 |

---

### 4. F1スコア（F1 Score）

PrecisionとRecallの調和平均で、偽陽性と偽陰性のバランスを評価します：

$$
F1 = 2 \times \frac{\mathrm{Precision} \times \mathrm{Recall}}{\mathrm{Precision} + \mathrm{Recall}}
$$

* PrecisionとRecallのバランスが悪いとき、低い方に引きずられる  
* クラス不均衡かつ偽陽性・偽陰性の両方を重視したい場合に適する  

---

### 5. 特殊な曲線と面積指標

1. **ROC曲線（Receiver Operating Characteristic）**

   * 横軸：偽陽性率 $\mathrm{FPR} = \frac{FP}{FP + TN}$  
   * 縦軸：真陽性率 $\mathrm{TPR} = \mathrm{Recall}$  
   * 曲線下の面積（AUC：Area Under Curve）は1に近いほど性能が良い。  

![](https://s.ar8.top/img/picgo/20250716170253975.webp) ![](https://s.ar8.top/img/picgo/20250716170322267.webp)

---

2. **PR曲線（Precision–Recall Curve）**

   * 横軸：Recall  
   * 縦軸：Precision  
   * クラス不均衡が極端な場合、PR曲線とその面積（Average Precision）の方が、正クラスの性能をより正確に反映する。  

![bg right:40% 90%](https://s.ar8.top/img/picgo/20250716173234347.webp)

---

## 二、回帰タスクの評価指標

### 1. 平均二乗誤差（MSE, Mean Squared Error）

$$
\mathrm{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat y_i)^2
$$

* 外れ値（大きな誤差）に敏感  
* 単位はラベルの二乗  

---

### 2. 平方根平均二乗誤差（RMSE, Root MSE）

$$
\mathrm{RMSE} = \sqrt{\mathrm{MSE}} = \sqrt{\frac{1}{n}\sum (y_i - \hat y_i)^2}
$$

* 元のラベルと同じ単位で、直感的に比較しやすい  

---

### 3. 平均絶対誤差（MAE, Mean Absolute Error）

$$
\mathrm{MAE} = \frac{1}{n}\sum_{i=1}^n |y_i - \hat y_i|
$$

* 外れ値への感度はMSEより低く、より頑健  

---

### 4. 決定係数（$R^2$ Score）

$$
R^2 = 1 - \frac{\sum_{i}(y_i - \hat y_i)^2}{\sum_{i}(y_i - \bar y)^2}
$$

* 値の範囲は固定されず、負になることもある（モデルが単純平均より悪い場合）  
* 1に近いほどデータへの適合度が高い  

---

## 三、適切な指標の選び方

1. **タスクの種類**  
   * 分類 vs. 回帰  

2. **ビジネス要件**  
   * 偽陽性（FP）と偽陰性（FN）どちらを重視するか？  
   * ある程度の外れ値誤差を許容できるか？  

3. **サンプル分布**  
   * クラス不均衡があるか？  

4. **解釈容易性**  
   * 単純な指標（Accuracy/MAE）は説明しやすい  
   * 複雑な指標（AUC/F1）は包括的だが直感性に欠ける  

---

## 四、なぜ交差検証が必要か

* **評価の安定性**：単一の訓練／テスト分割は偶然要素に左右されやすい  
* **データの有効活用**：サンプル数が限られる場合、各サンプルを訓練と検証に両方活用  
* **モデル比較とチューニング**：同一の分割方法で異なるモデルやハイパーパラメータを公平に比較  

---

## 五、代表的な交差検証手法

### 1. K-分割交差検証（K-Fold CV）

1. データセットをランダムに同等サイズの$K$個のfoldに分割  
2. $K$回の実験を実施：  
   * 第$i$回は$i$番目のfoldを検証用、残り$K-1$foldを訓練用に  
   * 各回の評価指標を記録（Accuracy、MSE、F1など）  
3. 最終的な性能は$K$回の評価指標の平均（および分散や標準偏差）  

> **推奨設定**：通常$K=5$または$10$。5-Foldは計算が早く、10-Foldはより安定。  

---

**長所**  
* 実装が簡単  
* 各foldを並列処理可能  

**短所**  
* $K$回のモデル訓練が必要なため、計算コストは単一分割の$K$倍  
* ランダム分割によりクラスやグループの相関が壊れることがある  

---

### 2. 層化抽出K-分割（Stratified K-Fold）

* 分類タスクで、各foldにおけるクラス比率を元のデータセットと同じに保つ  
* クラス不均衡が極端な場合、少数クラスの不足を防止  

**使用シーン**  
* 二値あるいは多クラス分類で、クラス分布が偏っている場合  

---

## 六、過学習と未学習

### 1. 概念

|            | 訓練データでの性能 | 検証／テストデータでの性能 |
| ---------- | ------------------ | -------------------------- |
| **未学習**   | 悪い（高誤差）       | 悪い（高誤差）               |
| **適切**     | 良い（低誤差）       | 良い（低誤差）               |
| **過学習**   | 非常に良い（極低誤差） | 悪い（高誤差）               |

* **未学習（Underfitting）**：モデルが単純すぎ、訓練データにも新データにも適合できない  
* **過学習（Overfitting）**：モデルが複雑すぎ、訓練データのノイズまで記憶してしまい、新データでは性能が落ちる  

--- 

### 2. バイアス–バリアンス視点

モデルの予測誤差は以下３つに分解できる：

$$
\mathbb{E}[(y - \hat f(x))^2] = \underbrace{\mathrm{Bias}^2}_{\text{バイアス}^2} + \underbrace{\mathrm{Variance}}_{\text{バリアンス}} + \underbrace{\sigma^2}_{\text{ノイズ}}
$$

* **Bias（バイアス）**：予測値の期待と真値のずれ。大きいほど未学習傾向  
* **Variance（バリアンス）**：予測のばらつき。大きいほど過学習傾向  
* **Noise（ノイズ）**：データ固有のランダム性で、どんなモデルでも除去不可  

複雑度と誤差の関係は通常「逆U字カーブ」：

* モデル複雑度 ↑ → Bias ↓, Variance ↑  
* **目標**：Bias²とVarianceのバランスを取り、総誤差を最小化  

---

### 3. 原因と診断

#### （1）未学習の原因と診断

* **原因**  
  * モデルが単純すぎる（線形モデルで高度非線形データを扱うなど）  
  * 特徴量が不足  
  * 正則化が強すぎる（λが大きい）  
* **診断**  
  * 訓練誤差が高く、検証誤差とほぼ同じ  
  * 学習曲線で訓練誤差が高止まり  

---

#### （2）過学習の原因と診断

* **原因**  
  * モデルが複雑すぎる（深い決定木、大量のパラメータなど）  
  * 特徴量にノイズが多い  
  * 訓練サンプルが少ない  
  * 正則化が弱いまたは欠如  
* **診断**  
  * 訓練誤差が非常に低い一方、検証誤差が大きく乖離  
  * 学習曲線で訓練誤差が下がり続け、検証誤差が途中から上昇  

---

### 4. 対策

#### （1）未学習への対策

* **モデル複雑度の向上**  
  * より柔軟なモデルへ（多項式回帰、決定木など）  
  * ニューラルネットワークの層・ノード数を増加  
* **特徴量エンジニアリング**  
  * 情報量のある特徴量を追加  
  * 多項式特徴や交互作用特徴の導入  
* **正則化の弱化**  
  * L1/L2正則化係数λの減少  

---

#### （2）過学習への対策

* **正則化**  
  * L2（Ridge）、L1（Lasso）、Elastic Net  
* **剪定・制限**  
  * 決定木：最大深度、最小分割サンプル数の制限  
  * ニューラルネット：Dropout、Early Stopping  
* **データ増強**  
  * サンプル数の増加  
  * データオーギュメンテーション（画像反転、ノイズ付加など）  

---

* **特徴選択**  
  * 有用性の低い特徴や高相関特徴の削除  
  * PCAなどで次元削減  
* **アンサンブル法**  
  * Bagging（ランダムフォレスト）は過学習に強い  
  * Boosting（XGBoostなど）は正則化を内包  

---

### 5. 例：学習曲線（Learning Curve）

訓練誤差と検証誤差を、訓練サンプル数やモデル複雑度に対してプロットすることで、未学習・過学習を直感的に判断できます：

![](https://s.ar8.top/img/picgo/20250716184851860.webp) ![](https://s.ar8.top/img/picgo/20250716184936472.webp)

* **未学習**：両曲線とも高く、ほぼ重なる  
* **過学習**：訓練誤差は低いが、検証誤差が高く差が大きい  
* **適切**：両曲線とも低く、近い  

---

> **まとめ**：  
>  
> * 未学習：モデルが単純 ⇒ 複雑度↑、特徴量充実、正則化↓  
> * 過学習：モデルが複雑 ⇒ 正則化↑、モデル制限、データ増強/アンサンブル  
> * Bias–Variance解析と学習曲線で診断し、チューニングをガイド  

---

## 七、ハイパーパラメータチューニング

### 1. パラメータ vs. ハイパーパラメータ

* **パラメータ（Parameters）**  
  訓練中にモデルが自動的に学習する値（例：線形回帰の重み$w$、ニューラルネットの重み・バイアス）  

* **ハイパーパラメータ（Hyperparameters）**  
  訓練前にユーザーが設定する値で、モデルが直接学習しない（例：決定木の`max_depth`、ランダムフォレストの`n_estimators`、学習率`learning_rate`、正則化係数λ、バッチサイズなど）  

ハイパーパラメータの選択はモデル性能に大きく影響するため、検証セットや交差検証を使って最適な組み合わせを見つけます。  

---

### 2. 主要なチューニング手法

| 手法            | 原理                                                        | 長所                             | 短所                                      |
| -------------- | ---------------------------------------------------------- | ------------------------------ | --------------------------------------- |
| **グリッドサーチ**    | 候補値のデカルト積を全探索し、それぞれを交差検証             | 実装簡単・並列化可能・再現性あり | 候補と次元数が増えると計算量爆発         |
| **ランダムサーチ**    | 定めた回数だけランダムに探索し、最良を記録                   | 同予算で広範囲探索が可能         | 探索回数を手動設定、重要でない領域も探索 |
| **ベイズ最適化**     | 代替モデル（Gaussian Processなど）を用い、履歴を元に賢く探索 | 少ない試行で最適に近い結果を得る | 実装複雑、代替モデル構築・更新のコスト    |

---

| 手法            | 原理                                                                 | 長所                                                         | 短所                                            |
| -------------- | ------------------------------------------------------------------- | ---------------------------------------------------------- | --------------------------------------------- |
| **Hyperband**  | Successive Halving思想で大量サンプルを高速評価・淘汰し、最適候補を絞る | 自動でリソース配分、低性能組み合わせを素早く排除            | 初期の性能変動に敏感、ランダムサーチより実装複雑 |
| **遺伝的アルゴリズム** | 自然選択を模倣し、交叉・突然変異でハイパーパラメータを進化                    | 大規模・離散・複雑空間に適、並列可能                         | 世代数・突然変異率などの設定が必要、収束遅いことも |
| **Optuna**     | TPEベースのモダンフレームワークで動的検索空間・分散並列・中断復帰対応            | API簡潔・自動化高・コミュニティ活発                         | フレームワーク習得が必要、ベイズ最適化類似の理解要   |

---

## 八、チューニング実践フロー

1. **検索空間の定義**  
   * ビジネス要件と経験に基づき、各ハイパーパラメータの候補範囲（離散集合 vs. 連続区間）を設定  
   * 例：  
     ```yaml
     max_depth: [3, 5, 7, 9]
     learning_rate: uniform(0.01, 0.3)
     n_estimators: [50, 100, 200]
     ```
2. **チューニング手法の選択**  
   * 予算が潤沢：グリッドサーチ  
   * 予算制限あり or パラメータ多：ランダムサーチ or Hyperband  
   * 試行回数を抑えたい：ベイズ最適化 or Optuna  

---

3. **交差検証の組み込み**  
   * 各ハイパーパラメータ組み合わせでK-分割交差検証を行い、平均スコアを取得  
   * scikit-learnの`GridSearchCV`/`RandomizedSearchCV`、Optunaなどを活用  
4. **記録と可視化**  
   * 各試行結果（組み合わせ＋検証スコア）を保存  
   * 熱マップ（グリッドサーチ）、散布図（ランダムサーチ）などで影響を可視化  

---

5. **最適組み合わせの決定**  
   * 目的指標（最高F1、最小RMSEなど）とその標準偏差を確認し、ベストを選択  
6. **最終モデルの再訓練**  
   * 全訓練データで最適ハイパーパラメータを用いて再訓練  
   * 独立テストデータで最終評価し、性能を確保  
