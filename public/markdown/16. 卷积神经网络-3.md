---
marp: true
theme: default
paginate: true
math: katex
---

<style>
section {
  font-family: "Microsoft YaHei", "PingFang SC", "Source Han Sans", "Noto Sans CJK SC", sans-serif;
}
</style>

# <!-- fit -->📘 第16讲：卷积神经网络 第 3 课

---

# 典型 CNN 架构
## 一、LeNet-5（1998）

### 背景

* 提出者：Yann LeCun 等人
* 应用：手写数字识别（MNIST 数据集）
* 意义：第一个成功应用 CNN 的模型，被认为是现代 CNN 的开山之作。

---

### 结构

* 输入：$32\times32$ 灰度图像
* C1：卷积层，6 个 $5\times5$ 卷积核 → 输出 $28\times28\times6$
* S2：池化层（亚采样），$2\times2$ 平均池化 → $14\times14\times6$
* C3：卷积层，16 个 $5\times5$ 卷积核 → $10\times10\times16$
* S4：池化层 → $5\times5\times16$
* C5：卷积层，120 个 $5\times5$ 卷积核 → $1\times1\times120$
* F6：全连接层（84 个神经元）
* 输出层：10 类分类（数字 0–9）

---

### 特点

* **卷积 + 池化交替**；
* **Sigmoid/Tanh 激活函数**（当时 ReLU 尚未提出）；
![w:2000](https://s.ar8.top/img/picgo/20250903164710294.webp)

---

## 二、AlexNet（2012）

### 背景

* ImageNet 2012 图像识别挑战赛冠军
* 将错误率从 26% 降至 15%，开启了深度学习热潮
* 作者：Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton

---

### 结构

* 输入：$224\times224\times3$ 彩色图像
* Conv1：$11\times11$ 卷积，stride=4 → 大感受野
* MaxPool：$3\times3$，stride=2
* Conv2：$5\times5$ 卷积，256 通道
* MaxPool
* Conv3–5：连续 $3\times3$ 卷积，分别为 384, 384, 256 通道
* MaxPool
* Flatten → 两层 FC（4096 神经元）
* 输出：1000 类 Softmax

---

### 创新点

* **ReLU 激活函数**：解决 Sigmoid/Tanh 饱和导致的梯度消失问题；
* **Dropout**：防止过拟合（应用在全连接层）；
* **数据增强**：随机裁剪、翻转、颜色扰动；
* **GPU 加速**：首次在 GPU 上大规模训练 CNN。

![h:380](https://s.ar8.top/img/picgo/20250903170413375.webp)

---

## 三、VGGNet（2014）

### 背景

* 牛津大学 Visual Geometry Group 提出
* 2014 ImageNet 挑战赛亚军
* 模型以结构简洁著称，被广泛用作特征提取 backbone。

---

### 结构

* 使用 **连续的小卷积核（$3\times3$）堆叠**替代大卷积核：

  * 例如，一个 $5\times5$ 卷积 ≈ 两个 $3\times3$ 卷积（感受野相同，但参数更少，非线性更多）
* VGG16 架构：13 个卷积层 + 3 个全连接层

  * Conv blocks：($3\times3$ 卷积，stride=1，padding=1) × 多次
  * MaxPool：$2\times2$，stride=2
  * FC1: 4096 → FC2: 4096 → 输出：1000

---

### 特点

* 统一使用 $3\times3$ 卷积和 $2\times2$ 池化；
* 层数加深（16/19 层），但结构规则易懂；
* 参数量大（约 138M），训练和存储开销大。

![w:2000 h:400](https://s.ar8.top/img/picgo/20250903172135127.webp)

---

## 四、GoogLeNet / Inception（2014）

### 背景

* Google 提出，2014 ImageNet 冠军
* 提出 **Inception 模块**，有效降低参数。

![](https://s.ar8.top/img/picgo/20250827194401865.webp)

---

### Inception 模块

* 输入 → 并行路径：

  * $1\times1$ 卷积（降维 + 特征压缩）
  * $1\times1$ → $3\times3$ 卷积
  * $1\times1$ → $5\times5$ 卷积
  * $3\times3$ 最大池化 → $1\times1$ 卷积
* 输出 → 通道拼接（concat）

---

### GoogLeNet 特点

* 22 层深度，但参数量仅 5M（比 VGG 小一个数量级）
* 大量使用 $1\times1$ 卷积减少计算量
* 在保证性能的同时，大幅提升了效率

---

## 五、ResNet（2015）

### 背景

* 微软研究院提出，2015 ImageNet 冠军
* 首次训练成功 **152 层深度网络**
* 解决了“深度网络退化”问题

---

### 残差连接（Residual Connection）

* 普通卷积块：$y=F(x)$
* 残差块：

$$
y = F(x) + x
$$

其中 $F(x)$ 是卷积层堆叠，$x$ 是输入的“shortcut connection”。

![bg right:50% 100%](https://s.ar8.top/img/picgo/20250827194731453.webp)

---

### 特点

* 残差连接让网络更容易训练（学习残差而不是完整函数）；
* 避免梯度消失，可训练数百层甚至更深；
* ResNet 成为现代深度学习模型 backbone 的主流选择。

---

## 六、其他重要架构

* **DenseNet（2017）**：每一层都与前面所有层相连，特征复用效率高；
* **MobileNet（2017）**：采用 **深度可分离卷积**，极大减少参数，适合移动端；
* **EfficientNet（2019）**：通过神经架构搜索 + 复合缩放策略（深度、宽度、分辨率同时调整），在参数量和性能间取得极佳平衡。

---


# CNN 的应用

---

## 一、图像分类（ImageNet 任务）

### 1. 任务定义

* 输入：一张图像
* 输出：类别标签（如「猫」「狗」「汽车」等）
* 本质：**单标签多分类问题**

---

### 2. ImageNet 挑战赛（ILSVRC）

* 数据集：1000 类，120 万训练图像
* 评价指标：**Top-1 / Top-5 准确率**
* 历史意义：

  * 2012 年 **AlexNet** 横空出世，Top-5 错误率从 26% 降至 15%，深度学习迅速崛起
  * 后续的 VGG、GoogLeNet、ResNet 等都在该赛场验证

---

### 3. 结构特点

* 典型分类网络（VGG/ResNet）：

  * **卷积 + 池化**：逐层提取特征
  * **全局平均池化（GAP）**：将空间特征压缩为通道特征
  * **全连接层 + Softmax**：输出类别概率

📌 图像分类是 CNN 最早、最成功的应用，也是许多其他任务的基础。

---

## 二、目标检测（Object Detection）

### 1. 任务定义

* 输入：一张图像
* 输出：多个物体的 **类别 + 边界框位置 (x,y,w,h)**
* 本质：**分类 + 回归** 的结合

---
![bg 70%](https://s.ar8.top/img/picgo/20250903173333070.webp)

---

![w:2000](https://s.ar8.top/img/picgo/20250903173449519.webp)

---

### 2. 发展脉络

1. **R-CNN (2014)**

   * 先用「候选区域」（Selective Search）生成约 2000 个候选框
   * 每个框裁剪 → CNN → SVM 分类
   * 问题：速度极慢（每张图几十秒）

2. **Fast R-CNN (2015)**

   * 整张图先经过 CNN 提取特征图
   * 用 RoI Pooling 从特征图中裁剪候选框
   * 显著加快速度

---

3. **Faster R-CNN (2015)**

   * 引入 **Region Proposal Network (RPN)**，替代手工候选框生成
   * 真正端到端训练，速度更快

4. **YOLO (2016)**

   * 「You Only Look Once」
   * 把目标检测转化为单次 CNN 前向推理：

     * 输入图像 → 分成网格
     * 每个网格预测边界框和类别
   * 实现实时检测（>30FPS）

---

5. **SSD (2016)**

   * 「Single Shot Multibox Detector」
   * 多尺度特征图上同时预测框
   * 更平衡精度与速度

### 3. 总结

* **两阶段方法**：R-CNN 家族（精度高，速度慢）
* **单阶段方法**：YOLO、SSD（速度快，适合实时应用）

---

## 三、语义分割（Semantic Segmentation）

### 1. 任务定义

* 输入：一张图像
* 输出：逐像素的类别标签（如区分“天空/道路/人/车”）
* 本质：**像素级分类**

---
![](https://s.ar8.top/img/picgo/20250903173825541.webp)

---

### 2. 代表模型

1. **FCN（Fully Convolutional Network, 2015）**

   * 去掉全连接层，全部用卷积层
   * 利用转置卷积（反卷积）进行上采样，恢复空间分辨率

2. **U-Net (2015)**

   * 编码器（下采样提取特征） + 解码器（上采样恢复分辨率）
   * 特点：**跳跃连接（skip connection）**，把编码器的浅层特征直接传给解码器，提高边界细节

3. **DeepLab 系列（2016+）**

   * 使用 **空洞卷积 (Dilated Convolution)** 扩大感受野
   * 提出 **条件随机场 (CRF)** 后处理和 **ASPP (Atrous Spatial Pyramid Pooling)** 多尺度融合

---

![](https://s.ar8.top/img/picgo/20250903174012390.webp)
![](https://s.ar8.top/img/picgo/20250903174040041.webp)

---
### 3. 应用

* 自动驾驶（车道线/路障识别）
* 医学图像（肿瘤区域分割）
* 卫星遥感（地物分类）

---

## 四、生成对抗网络（GAN）中的卷积应用

### 1. GAN 简介

* 提出者：Ian Goodfellow（2014）
* 两个网络：

  * **生成器 G**：从随机噪声生成假图像
  * **判别器 D**：判断图像是真还是假
* 训练目标：G 欺骗 D，D 尽力分辨

---
![](https://s.ar8.top/img/picgo/20250903174541508.webp)

---

![](https://s.ar8.top/img/picgo/20250903174728681.webp)

---

![](https://s.ar8.top/img/picgo/20250903174806903.webp)

---

### 2. 卷积在 GAN 中的作用

* **DCGAN (Deep Convolutional GAN, 2015)**

  * 用卷积网络替代全连接层：

    * 判别器 D：类似 CNN 分类器（Conv + Pooling）
    * 生成器 G：使用转置卷积（上采样），从低维向量生成高分辨率图像

* 典型结构：

  * 判别器：Conv → BN → LeakyReLU → Conv → … → Sigmoid
  * 生成器：FC → 转置卷积 → BN → ReLU → 转置卷积 → Tanh

---

### 3. 应用

* 图像生成（人脸、艺术风格）
* 图像修复（Inpainting）
* 图像超分辨率（Super-Resolution）

---

# 总结与展望

---

## 一、从传统 CNN 到 Transformer（ViT）的过渡

### 1. 传统 CNN 的地位

* CNN 自 **LeNet-5 (1998)** 至 **ResNet (2015)**，一直是视觉任务的主力模型；
* 擅长局部特征提取，具有 **平移不变性** 和 **高效的参数共享**；
* 在 **图像分类、目标检测、分割** 等任务中表现卓越。

---

### 2. Transformer 的引入

* 最早应用于 **自然语言处理（NLP）**：Vaswani 等人提出的 **Attention Is All You Need (2017)**；
* 2020 年，Google 提出 **Vision Transformer (ViT)**，将 Transformer 架构迁移到图像：

  * 把图像切分为固定大小的 patch（如 $16\times16$），展平后作为序列输入；
  * 使用自注意力机制（Self-Attention）学习全局关系，而非局部卷积。

---

### 3. 对比 CNN 与 ViT

* **CNN**：

  * 优势：局部感知、参数效率高、易于小数据训练
  * 劣势：难以捕捉全局依赖，需要更深层或更复杂设计
* **ViT**：

  * 优势：天然建模全局关系，更适合大规模数据
  * 劣势：训练需要海量数据和计算资源，小数据集性能可能不及 CNN

---

## 二、CNN 仍广泛用于特征提取和轻量模型

### 1. 现实中的应用需求

* 移动端、嵌入式设备：功耗、速度要求高
* 自动驾驶、监控、医疗：需要稳定、可解释的特征提取

### 2. CNN 的价值

* **特征提取器**：在许多混合架构中，CNN 仍被用作低层次特征提取模块，Transformer 接收 CNN 特征作为输入（Hybrid CNN-Transformer）。
* **轻量化模型**：MobileNet、ShuffleNet、EfficientNet 等 CNN 变体，仍然是手机、IoT 等设备中的主流。
* **蒸馏与压缩**：即使是 Transformer 模型，也常通过知识蒸馏到 CNN，以便部署。

---

## 三、未来趋势

* **CNN 与 Transformer 融合**：

  * 例如 ConvNeXt（2022），用纯 CNN 模拟 Transformer 的训练范式；
  * Swin Transformer 等模型则结合卷积思想（层级结构、局部窗口）。
* **高效化与自动化**：

  * 神经架构搜索（NAS）自动设计 CNN/Transformer 结构；
  * 更注重参数效率与推理速度。
* **跨模态应用**：

  * CNN 仍在视频分析、医学影像、遥感图像等领域发挥不可替代作用。

