---
marp: true
theme: default
paginate: true
math: katex
---

<style>
section {
  font-family: "Microsoft YaHei", "PingFang SC", "Source Han Sans", "Noto Sans CJK SC", sans-serif;
}
</style>

# <!-- fit -->📘 第16講：畳み込みニューラルネットワーク（CNN） 第3課

---

# 典型的な CNN アーキテクチャ
## 一、LeNet-5（1998）

### 背景

* 提案者：Yann LeCun ら
* 応用：手書き数字認識（MNIST データセット）
* 意義：CNN を初めて成功裏に応用したモデルであり、現代 CNN の先駆けとされる。

---

### 構造

* 入力：$32\times32$ グレースケール画像
* C1：畳み込み層、6 個の $5\times5$ カーネル → 出力 $28\times28\times6$
* S2：プーリング層（サブサンプリング）、$2\times2$ 平均プーリング → $14\times14\times6$
* C3：畳み込み層、16 個の $5\times5$ カーネル → $10\times10\times16$
* S4：プーリング層 → $5\times5\times16$
* C5：畳み込み層、120 個の $5\times5$ カーネル → $1\times1\times120$
* F6：全結合層（84 ニューロン）
* 出力層：10 クラス分類（数字 0–9）

---

### 特徴

* **畳み込み＋プーリングの交互構造**
* **Sigmoid/Tanh 活性化関数**（当時は ReLU が未提案）

![w:2000](https://s.ar8.top/img/picgo/20250903164710294.webp)

---

## 二、AlexNet（2012）

### 背景

* ImageNet 2012 画像認識チャレンジ優勝
* 誤り率を 26% から 15% に低減し、ディープラーニングブームを加速
* 著者：Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton

---

### 構造

* 入力：$224\times224\times3$ カラー画像
* Conv1：$11\times11$ 畳み込み、stride=4 → 大きな受容野
* MaxPool：$3\times3$，stride=2
* Conv2：$5\times5$ 畳み込み、256 チャンネル
* MaxPool
* Conv3–5：連続 $3\times3$ 畳み込み、384, 384, 256 チャンネル
* MaxPool
* Flatten → 全結合層 2 層（4096 ニューロン）
* 出力：1000 クラス Softmax

---

### 革新点

* **ReLU 活性化関数**：Sigmoid/Tanh 飽和による勾配消失を解決
* **Dropout**：過学習防止（全結合層に適用）
* **データ拡張**：ランダムクロップ、反転、色の摂動
* **GPU 加速**：初めて GPU 上で大規模 CNN 学習を実現

![h:380](https://s.ar8.top/img/picgo/20250903170413375.webp)

---

## 三、VGGNet（2014）

### 背景

* オックスフォード大学 Visual Geometry Group により提案
* 2014 ImageNet チャレンジ準優勝
* 構造の単純さで知られ、特徴抽出 backbone として広く利用

---

### 構造

* **小さな畳み込み核（$3\times3$）を連続して積み重ね**、大きなカーネルを代替：

  * 例：$5\times5$ 畳み込み ≈ 連続する $3\times3$ 畳み込み 2 回（同じ受容野、パラメータは少ない、非線形性は多い）
* VGG16 構造：13 畳み込み層 + 3 全結合層

  * Conv ブロック：($3\times3$ 畳み込み, stride=1, padding=1) × 複数
  * MaxPool：$2\times2$, stride=2
  * FC1: 4096 → FC2: 4096 → 出力：1000

---

### 特徴

* 全ての層で $3\times3$ 畳み込みと $2\times2$ プーリングを使用
* 層を深く（16/19 層）するが、規則的で理解しやすい構造
* パラメータ数が非常に多い（約 1.38 億）、学習・保存コストが大きい

![w:2000 h:400](https://s.ar8.top/img/picgo/20250903172135127.webp)

---

## 四、GoogLeNet / Inception（2014）

### 背景

* Google が提案、2014 ImageNet 優勝
* **Inception モジュール**を導入し、パラメータ削減を実現

![](https://s.ar8.top/img/picgo/20250827194401865.webp)

---

### Inception モジュール

* 入力 → 並列経路：

  * $1\times1$ 畳み込み（次元削減＋特徴圧縮）
  * $1\times1$ → $3\times3$ 畳み込み
  * $1\times1$ → $5\times5$ 畳み込み
  * $3\times3$ 最大プーリング → $1\times1$ 畳み込み
* 出力 → チャンネル結合（concat）

---

### GoogLeNet 特徴

* 22 層の深さを持つが、パラメータ数はわずか 500 万（VGG の約 1/10）
* $1\times1$ 畳み込みを多用し計算量を削減
* 高性能を維持しつつ効率を大幅に向上

---

## 五、ResNet（2015）

### 背景

* Microsoft Research によって提案、2015 ImageNet 優勝
* **152 層の深層ネットワーク**の学習に初めて成功
* 「深層ネットワーク劣化問題」を解決

---

### 残差接続（Residual Connection）

* 通常の畳み込みブロック：$y=F(x)$
* 残差ブロック：

$$
y = F(x) + x
$$

ここで $F(x)$ は畳み込み層スタック、$x$ は入力の「ショートカット接続」

![bg right:50% 100%](https://s.ar8.top/img/picgo/20250827194731453.webp)

---

### 特徴

* 残差接続により学習が容易（完全な関数ではなく残差を学習）
* 勾配消失を回避し、数百層以上の学習が可能
* ResNet は現代ディープラーニングの backbone として主流に

---

## 六、その他の重要アーキテクチャ

* **DenseNet（2017）**：各層が前層すべてと接続し、特徴再利用効率が高い
* **MobileNet（2017）**：**深層分離畳み込み**を採用し、パラメータを大幅削減、モバイル向けに適する
* **EfficientNet（2019）**：ニューラルアーキテクチャ探索＋複合スケーリング（深さ・幅・解像度を同時調整）で性能と効率の最適化

---

# CNN の応用

---

## 一、画像分類（ImageNet タスク）

### 1. タスク定義

* 入力：1 枚の画像
* 出力：カテゴリラベル（例：「猫」「犬」「車」など）
* 本質：**単一ラベル多クラス分類問題**

---

### 2. ImageNet チャレンジ（ILSVRC）

* データセット：1000 クラス、120 万枚の訓練画像
* 評価指標：**Top-1 / Top-5 精度**
* 歴史的意義：

  * 2012 年 **AlexNet** が登場、Top-5 誤り率を 26% → 15% に改善し、ディープラーニング勃興
  * その後 VGG、GoogLeNet、ResNet などが同舞台で検証

---

### 3. 構造的特徴

* 典型的な分類ネットワーク（VGG/ResNet）：

  * **畳み込み＋プーリング**：階層的に特徴抽出
  * **グローバル平均プーリング（GAP）**：空間特徴をチャネル特徴に圧縮
  * **全結合層＋Softmax**：クラス確率を出力

📌 画像分類は CNN の最も初期かつ成功した応用であり、多くのタスクの基盤。

---

## 二、物体検出（Object Detection）

### 1. タスク定義

* 入力：1 枚の画像
* 出力：複数物体の **クラス＋バウンディングボックス (x,y,w,h)**
* 本質：**分類＋回帰** の組み合わせ

---
![bg 70%](https://s.ar8.top/img/picgo/20250903173333070.webp)

---

![w:2000](https://s.ar8.top/img/picgo/20250903173449519.webp)

---

### 2. 発展経緯

1. **R-CNN (2014)**

   * 「候補領域」（Selective Search）で約 2000 箇所を生成
   * 各領域を切り取り → CNN → SVM 分類
   * 問題：非常に遅い（1 枚数十秒）

2. **Fast R-CNN (2015)**

   * 画像全体を CNN で特徴マップ化
   * RoI Pooling で候補領域を抽出
   * 速度が大幅改善

---

3. **Faster R-CNN (2015)**

   * **Region Proposal Network (RPN)** を導入、候補領域生成を置換
   * 真のエンドツーエンド学習、速度さらに向上

4. **YOLO (2016)**

   * 「You Only Look Once」
   * 物体検出を単一 CNN 推論に変換：

     * 入力画像 → グリッド分割
     * 各グリッドがバウンディングボックスとクラスを予測
   * リアルタイム検出（>30FPS）を実現

---

5. **SSD (2016)**

   * 「Single Shot Multibox Detector」
   * 複数スケールの特徴マップで同時にボックス予測
   * 精度と速度のバランスが良い

### 3. まとめ

* **二段階手法**：R-CNN 系列（高精度、低速）
* **一段階手法**：YOLO、SSD（高速、リアルタイムに適す）

---

## 三、セマンティックセグメンテーション（Semantic Segmentation）

### 1. タスク定義

* 入力：1 枚の画像
* 出力：画素ごとのクラスラベル（例：「空」「道路」「人」「車」）
* 本質：**ピクセルレベル分類**

---
![](https://s.ar8.top/img/picgo/20250903173825541.webp)

---

### 2. 代表モデル

1. **FCN（Fully Convolutional Network, 2015）**

   * 全結合層を排除し、全て畳み込み層
   * 転置畳み込み（逆畳み込み）でアップサンプリングし空間解像度を復元

2. **U-Net (2015)**

   * エンコーダ（下サンプリングで特徴抽出）＋デコーダ（アップサンプリングで解像度復元）
   * 特徴：**スキップ接続**により浅層特徴をデコーダへ直接伝達、境界の精度向上

3. **DeepLab シリーズ（2016+）**

   * **空洞畳み込み (Dilated Convolution)** で受容野を拡大
   * **CRF** 後処理や **ASPP** による多スケール融合を導入

---

![](https://s.ar8.top/img/picgo/20250903174012390.webp)
![](https://s.ar8.top/img/picgo/20250903174040041.webp)

---
### 3. 応用

* 自動運転（車線・障害物認識）
* 医用画像（腫瘍領域分割）
* 衛星リモートセンシング（地物分類）

---

## 四、GAN における畳み込みの応用

### 1. GAN 概要

* 提案者：Ian Goodfellow（2014）
* 2 つのネットワーク：

  * **生成器 G**：ランダムノイズから偽画像を生成
  * **識別器 D**：画像が本物か偽物かを判定
* 学習目標：G が D を欺き、D が正しく識別するよう競合

---
![](https://s.ar8.top/img/picgo/20250903174541508.webp)

---

![](https://s.ar8.top/img/picgo/20250903174728681.webp)

---

![](https://s.ar8.top/img/picgo/20250903174806903.webp)

---

### 2. 畳み込みの役割

* **DCGAN (Deep Convolutional GAN, 2015)**

  * 全結合層の代わりに畳み込みを採用：

    * 識別器 D：CNN 分類器に類似（Conv + Pooling）
    * 生成器 G：転置畳み込み（アップサンプリング）で高解像度画像を生成

* 典型構造：

  * 識別器：Conv → BN → LeakyReLU → Conv → … → Sigmoid
  * 生成器：FC → 転置畳み込み → BN → ReLU → 転置畳み込み → Tanh

---

### 3. 応用

* 画像生成（顔、アートスタイル）
* 画像修復（Inpainting）
* 画像超解像（Super-Resolution）

---

# まとめと展望

---

## 一、従来 CNN から Transformer（ViT）への移行

### 1. 従来 CNN の地位

* CNN は **LeNet-5 (1998)** から **ResNet (2015)** まで視覚タスクの主力
* 局所特徴抽出に強く、**平行移動不変性** と **効率的なパラメータ共有** を持つ
* **画像分類・物体検出・分割** で高性能

---

### 2. Transformer の導入

* 最初は **自然言語処理（NLP）** に適用：Vaswani ら「Attention Is All You Need (2017)」
* 2020 年、Google が **Vision Transformer (ViT)** を提案、画像に Transformer を適用：

  * 画像を $16\times16$ パッチに分割し、系列入力に変換
  * **自己注意機構（Self-Attention）** で局所ではなくグローバル関係を学習

---

### 3. CNN と ViT の比較

* **CNN**：

  * 長所：局所感知、パラメータ効率、小規模データでも訓練容易
  * 短所：グローバル依存を捉えにくく、深層化や複雑化が必要
* **ViT**：

  * 長所：グローバル関係を自然にモデル化、大規模データに適する
  * 短所：膨大なデータと計算資源が必要、小規模データでは CNN より劣る場合あり

---

## 二、CNN は依然として特徴抽出・軽量モデルに広く利用

### 1. 現実的応用ニーズ

* モバイル・組込み機器：低消費電力・高速処理
* 自動運転・監視・医療：安定かつ解釈可能な特徴抽出が必要

### 2. CNN の価値

* **特徴抽出器**：多くのハイブリッド構造で低層特徴抽出モジュールとして利用、Transformer は CNN 特徴を入力に利用（Hybrid CNN-Transformer）
* **軽量モデル**：MobileNet、ShuffleNet、EfficientNet などの CNN 変種は依然としてスマホ・IoT デバイスの主流
* **蒸留と圧縮**：Transformer モデルも知識蒸留により CNN へ圧縮され、デプロイ容易化

---

## 三、将来動向

* **CNN と Transformer の融合**：

  * ConvNeXt（2022）：純 CNN で Transformer の学習パラダイムを模倣
  * Swin Transformer などは畳み込みの思想（階層構造・局所ウィンドウ）を導入
* **効率化と自動化**：

  * ニューラルアーキテクチャ探索（NAS）で CNN/Transformer を自動設計
  * パラメータ効率・推論速度を重視
* **クロスモーダル応用**：

  * CNN は動画解析・医用画像・リモートセンシングなどで不可欠な役割を継続

