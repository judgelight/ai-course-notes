---
marp: true
theme: default
paginate: true
math: katex
---

<style>
section {
  font-family: "Microsoft YaHei", "PingFang SC", "Source Han Sans", "Noto Sans CJK SC", sans-serif;
}
</style>

# <!-- fit -->📘 第15講：畳み込みニューラルネットワーク 第2課

---

## 一、畳み込み層のバリエーション

### 1. 深層分離可能畳み込み（Depthwise Separable Convolution）

**アイデア**：標準的な畳み込みを2段階に分解する。

1. **Depthwise Convolution（逐チャネル畳み込み）**：各入力チャネルごとに独立したフィルタで空間的な畳み込みを行う（チャネルを混合しない）。
2. **Pointwise Convolution（逐点畳み込み, 1×1 畳み込み）**：$1\times1$ 畳み込みでチャネルを線形結合し、チャネル融合を行う。

---

![](https://s.ar8.top/img/picgo/20250827185623703.webp)

---

**パラメータ数の比較**：

* 標準畳み込み：

$$
\#params = K_h \cdot K_w \cdot C_{in} \cdot C_{out}
$$

* 深層分離可能畳み込み：

$$
\#params = K_h \cdot K_w \cdot C_{in} \;+\; C_{in} \cdot C_{out}
$$

---

**例**：

* 入力 $224\times224\times32$、カーネル $3\times3$、出力チャネル $64$ の場合：

  * 標準畳み込みパラメータ数 ≈ $3\times3\times32\times64 = 18,432$
  * 深層分離可能畳み込みパラメータ数 ≈ $3\times3\times32 + 32\times64 = 288 + 2048 = 2336$
    → **約8倍** のパラメータ削減。

**応用**：

* モバイル向け軽量ネットワーク（MobileNet、Xception）。

---

### 2. 空洞畳み込み（Dilated Convolution / Atrous Convolution）

**定義**：フィルタ内に「空洞（dilation）」を挿入し、入力特徴マップを間引きサンプリングする畳み込み。

* 有効なカーネルサイズ：

$$
K^{eff} = D\cdot(K-1) + 1
$$

ここで $D$ は膨張率（dilation rate）。

![bg right:40% 100%](https://s.ar8.top/img/picgo/20250827190216155.webp)

---

**効果**：

* 受容野（RF）が拡大し、パラメータや計算量を増やさずに広域情報を取得可能。
* 高解像度を維持したままグローバル文脈を捉えられる。

**応用**：

* セマンティックセグメンテーション（DeepLab 系列）、分解能を落とさずに全局情報を活用。

---

### 3. 転置畳み込み（Transposed Convolution / Deconvolution）

**動機**：生成モデルやセグメンテーションで、低解像度特徴から高解像度特徴を復元する「アップサンプリング」が必要。

**定義**：転置畳み込みは通常の畳み込みの「逆伝播形式」。入力の間にゼロを挿入して畳み込みを行い、特徴マップを拡大する。

![](https://s.ar8.top/img/picgo/20250827191156988.webp)

---

**出力サイズの公式**（1次元の場合）：

$$
H_{out} = (H_{in}-1)\cdot S - 2P + D\cdot (K-1) + \text{output\_padding} + 1
$$

* $H\_{\text{in}}$：入力サイズ
* $S$：ストライド
* $P$：パディング（正方向の畳み込みでの定義を逆に適用）
* $K$：カーネルサイズ
* $D$：dilation（空洞率）
* $\text{output\_padding}$：転置畳み込み特有の補正項
* 最後の **+1** は離散畳み込みのインデックス境界による定数項

---

**問題点**：チェッカーボードアーティファクトが発生しやすい。

**代替手法**：アップサンプリング（最近傍/双線形補間）＋通常の畳み込み（より安定）。

**応用**：

* GAN、画像セグメンテーション（FCN, U-Net）。

---

# 代替手法の詳細：転置畳み込みを使わずにアップサンプリング

多くのタスク（セグメンテーション、生成）で特徴マップの拡大が必要だが、転置畳み込みは**チェッカーボードアーティファクト**を引き起こすことがある。そのため以下の手法が実務で多用される。

---

## 方法 A：アップサンプリング（補間）＋通常畳み込み（Resize-Conv / UpSample-Conv）

* 先に補間で特征図を拡大し、その後標準畳み込みで整形。
* 補間方式：`nearest`（高速）、`bilinear`/`bicubic`（平滑）、`area`（平均プーリング逆変換に近い）。
* **利点**：アーティファクトがほぼ出ない、実装が容易。

PyTorch例：

```python
import torch.nn.functional as F
up = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
y  = conv3x3(up)
```

---

## 方法 B：ピクセルシャッフル（Sub-Pixel / PixelShuffle）

* チャネル数を $r^2$ 倍に増加させ、チャネルを空間方向に再配置。
* 代表例：ESPCN / PixelShuffle（超解像）。
* **利点**：高効率、アーティファクトなし。
* **課題**：チャネル構造に制約あり、ICNR 初期化が望ましい。

PyTorch例：

```python
conv = nn.Conv2d(C_in, C_out * r * r, kernel_size=3, padding=1)
shuffle = nn.PixelShuffle(r)
y = shuffle(conv(x))
```

---

## 方法 C：逆プーリング（MaxUnpool）

* 下采样に **MaxPool2d(return\_indices=True)** を使用し、上采样で **MaxUnpool2d** により元の位置へ復元。
* **利点**：可逆性が強く、直感的（SegNet）。
* **制約**：プーリング時のインデックス保存が必須。

---

## 方法 D：段階的アップサンプリング（×2 を繰り返す）

* 一気に ×4/×8 せず、×2 を繰り返して拡大。
* **利点**：安定的に細部を段階的に復元、U-Net 風のスキップ接続に適合。

---

## 方法 E：動的/学習可能補間（CARAFE など）

* 局所文脈に応じてアップサンプリングカーネルを動的生成。
* **利点**：高品質な復元。
* **課題**：計算コストが増加。

---

## 二、アップサンプリングとダウンサンプリング

CNN における **サンプリング** は特徴マップの空間解像度（H×W）を変化させる操作。

### 1. ダウンサンプリング（Downsampling）

**定義**：特徴マップの空間分解能を縮小（H↓, W↓）。
**効果**：

* 計算量削減
* 受容野拡大
* 平行移動不変性の向上

**代表手法**：

1. 最大プーリング（Max Pooling）
2. 平均プーリング（Average Pooling）
3. ストライド畳み込み

---

### 2. アップサンプリング（Upsampling）

**定義**：特徴マップの空間解像度を拡大（H↑, W↑）。
**効果**：

* セグメンテーション、生成、検出で高解像度出力を可能に。

**代表手法**：

1. 最近傍補間
2. 双線形補間
3. 転置畳み込み
4. アップサンプリング＋通常畳み込み

---

## 三、畳み込み構造の改良事例

### (一) Inception モジュール（GoogLeNet, 2014）

#### 1. 背景

* 異なるカーネルサイズは異なる受容野を持つ：

  * 小さいカーネル（$1\times1$, $3\times3$） → 細部
  * 大きいカーネル（$5\times5$） → 広域文脈
* 課題：多種類のカーネルを積層すると計算量とパラメータが膨大。

---

#### 2. Inception のアイデア

* **並列マルチスケール畳み込み**：$1\times1$, $3\times3$, $5\times5$ 畳み込みと $3\times3$ プーリングを並列適用。
* **1×1 畳み込みによる次元削減**：大きい畳み込みの前に $1\times1$ 畳み込みを使いチャネル数を削減。

---

#### 3. 構造図

![](https://s.ar8.top/img/picgo/20250827194401865.webp)

---

#### 4. 利点

* マルチスケール特徴の融合
* 1×1 畳み込みで計算削減
* 表現力向上しつつ計算効率維持

#### 5. 応用

* GoogLeNet（Inception v1）：パラメータ約500万（AlexNetは約6000万）。
* 後続の v2/v3 では畳み込み分解や正則化を改良。

---

### (二) ResNet 残差ネットワーク（2015）

#### 1. 背景

* ネットワークを深くすると訓練困難：

  * **勾配消失/爆発**
  * **劣化問題**：深くしても精度低下

---

#### 2. 残差学習のアイデア

* 直接 $H(x)$ を学習するのは困難。
* 残差関数 $F(x) = H(x) - x$ を学習する：

$$
H(x) = F(x) + x
$$

* 出力 = 入力 + 残差

---

#### 3. 残差ブロック（Residual Block）

![bg right:50% 100%](https://s.ar8.top/img/picgo/20250827194731453.webp)

数式表現：

$$
y = F(x, W) + x
$$

---

#### 4. 利点

* 勾配消失を緩和し、数百層～千層以上の訓練を可能に。
* 恒等写像に近い最適解を残差として学習できるため最適化が容易。

---

#### 5. 実装の注意点

* 入力出力の次元が異なる場合は $1\times1$ 畳み込みで調整。
* ResNet v2 では **BN → ReLU → Conv** の順序（pre-activation）が効果的。

#### 6. 応用

* ResNet は 2015 年 ImageNet 優勝（152層）、DLの重要なマイルストーン。
* 多くの後続モデル（DenseNet, ResNeXt, Transformers）に影響。

