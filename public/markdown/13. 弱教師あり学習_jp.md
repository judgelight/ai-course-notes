---
marp: true
theme: default
paginate: true
math: katex
---

<style>
section {
  font-family: "Microsoft YaHei", "PingFang SC", "Source Han Sans", "Noto Sans CJK SC", sans-serif;
}
</style>


# <!-- fit -->📘 第13講：弱教師あり学習

---

## 1. 概念と定義

**弱教師あり学習（Weakly Supervised Learning, WSL）**

学習時に**不完全・不正確・または誤ったラベル**を含むデータを用いてモデル化を行う機械学習手法の一種。  
**完全教師あり学習**（完全に正確なラベル）と**教師なし学習**（ラベルなし）の中間に位置し、  
ラベルの質に欠陥があっても安価に大量に取得できるデータを最大限活用することを目的とする。

---

## 2. 3つの主要タイプ

1. **不完全教師（Incomplete Supervision）**

   * サンプルのごく一部のみ高品質なラベルがあり、それ以外はラベルなし。
   * 例：100万枚の画像のうち、5万枚のみ人工でラベル付けされている。

2. **不精確教師（Inexact Supervision）**

   * ラベルの粒度が粗く、学習タスクの正確な要件を直接満たさない。
   * 例：画像全体のカテゴリラベルはあるが、タスクは物体検出（位置情報が必要）。

3. **不正確教師（Inaccurate Supervision）**

   * ラベルにノイズや誤りが含まれる。
   * 例：Webスクレイピングで取得した画像のラベル誤り率が高い。

---

## 3. 主な応用シナリオ

* **医用画像**：精密なアノテーションは限られており、粗粒度の診断ラベルが大量に存在。
* **検索・推薦**：クリックや滞在時間を弱ラベルとして使用（必ずしも真の興味とは限らない）。
* **Webデータ自動収集**：クローラ＋キーワードマッチで生成したラベルは精度が低い。
* **遠隔教師（Distant Supervision）**：外部知識ベースを使って自動でラベル付け。

---

## 4. 一般的な実装プロセス

### Step 1：データ取得

* 出典：Webクローラ、ログ行動、知識ベースのマッピング、半自動ラベリングツール。
* 一部の高品質人工ラベルを検証用に保持。

### Step 2：データクリーニングと品質評価

* **ルールベースフィルタ**：明らかに誤っているデータを除去。
* **ベースラインモデルによる選別**：低信頼度サンプルを初期段階で除外。
* **ノイズ率推定**：少量の人工ラベルを用いて弱ラベルの精度を評価。

---

### Step 3：ラベル強化と修正

* **擬似ラベル（Pseudo-labeling）**：初期モデルで未ラベルデータを予測し、高信頼度サンプルを採用。
* **ラベルスムージング（Label Smoothing）**：誤ラベルの影響を減らす。
* **マルチソース統合**：重み付き投票やベイズ統合で複数ラベルソースを融合。

### Step 4：学習戦略

* **ノイズ耐性損失関数**：MAE、Bootstrap Loss、Focal Loss。
* **半教師ありとの併用**：MixMatch、FixMatch、Mean Teacher。
* **マルチタスク学習**：付随する弱ラベル情報を補助タスクとして活用。

---

### Step 5：モデル評価

* 高品質な検証セットを使用。
* 評価指標はタスク依存：Accuracy / F1 / mAP / ROC-AUC など。

### Step 6：デプロイと反復

* 本番運用後も継続的に新データを収集。
* 増分学習（Incremental Learning）。
* 能動学習（Active Learning）で不確実なサンプルをラベル付け。

---

## 5. よく使われる手法と技術

| 課題         | 手法例                                         | 核心アイデア           |
| ------------ | --------------------------------------------- | ---------------------- |
| ノイズラベル | Bootstrap Loss, Co-teaching                    | 誤ラベルの悪影響を低減   |
| 粗粒度ラベル | Multiple Instance Learning (MIL)               | バッグ（bag）単位のラベルからインスタンスラベルを推定 |
| 部分ラベル   | Pseudo-labeling, Consistency Regularization    | 未ラベルデータにラベルを生成 |
| ラベル融合   | Majority Voting, Bayesian Label Fusion         | 複数ソースラベル統合で精度向上 |

---

## 6. Bootstrap Loss 詳解

**1）数式定義**  
二値分類において、Bootstrap Loss は現在の**弱ラベル**（誤りを含む可能性あり）と  
モデル自身の予測結果を融合して**ソフトラベル**を生成する：

$$
y_\text{soft} = \beta \cdot y_\text{noisy} + (1 - \beta) \cdot p_\text{detach}
$$

* $y_\text{noisy}$：弱ラベル（ノイズを含む可能性あり）  
* $p_\text{detach}$：モデルの現在の予測（勾配は逆伝播しない）  
* $\beta \in [0,1]$：融合係数  

最終的に **BCE損失** で計算：

$$
\mathcal{L} = \text{BCE}(p, y_\text{soft})
$$

---

**2）誤ラベルの支配力をどう低減するか？**

* 通常のクロスエントロピーでは、弱ラベルが唯一の学習信号であり、誤っている場合は誤学習を強制される。
* Bootstrap Loss は $(1-\beta)$ の割合をモデル自身の予測に置き換えることで、**誤ラベルの損失への影響を減らす**。
* 正しいラベルのサンプルでは、予測とラベルが一致し融合結果はほぼ正解値。
* 誤ラベルのサンプルでは、予測がラベルと異なることが多く、融合後はより妥当な値に引き戻され、勾配の誤誘導を軽減。

---

**3）適用シナリオ**

* ラベルノイズがランダムで完全には除去できない場合（Webスクレイピング、ユーザ行動ログなど）。
* 大多数のサンプルで信頼度の高い予測ができる安定したモデルを事前に訓練できる場合。

---

**4）ハイパーパラメータ $\beta$ の影響**

* $\beta \to 1$：ラベル依存が強く（耐性弱）
* $\beta \to 0$：予測依存が強く（誤った自己強化の可能性）
* 一般的な値：0.6 – 0.9（検証セットで調整）

---

## 7. 弱教師あり学習 vs 半教師あり学習

| 観点         | 弱教師あり学習（WSL）             | 半教師あり学習（SSL）            |
| ------------ | -------------------------------- | --------------------------------- |
| ラベル問題の起源 | 欠損・粗粒度・ノイズを含む        | 主に欠損ラベル（部分的にラベルなし）|
| データ品質   | 低品質ラベルが多い                 | ラベル付き部分は高品質              |
| 代表的手法   | ノイズ耐性損失・ラベル修正・多インスタンス学習 | 一貫性正則化・擬似ラベル・自己学習   |
| 注力点       | 不完全ラベルの活用                 | 未ラベルデータの活用                 |
| シナリオ     | クローラデータ・遠隔教師・弱ラベル検出 | 宿題採点・一部精密ラベル＋大部分ラベルなし |
| 難しさ       | ラベルノイズ処理・粒度の曖昧さ       | 擬似ラベルによる誤誘導の防止           |

---

> **まとめ**：半教師あり学習は弱教師あり学習の一部（不完全教師の一種）であり、弱教師あり学習はより広い範囲のラベル問題を扱う。

---

## 8. 応用例

1. **画像分類（ノイズラベル）**

   * Webから猫犬画像を収集 → 5%を人工ラベル → ノイズ耐性学習。
2. **医用画像（粗粒度ラベル）**

   * 患者の疾患有無（画像全体ラベル）のみ → 病巣の位置特定が目標。
3. **検索ランキング（行動ログ）**

   * クリック/滞在時間を弱ラベルとしてCTR予測モデルを学習。

---

## 9. 重要ポイントまとめ

* 弱教師あり学習は**安価だが不完全なデータ**でモデルを学習可能にする。
* 3つの課題：**ラベル欠損**・**粒度不精確**・**ラベルノイズ**。
* 実装の鍵：

  1. データクリーニングと品質評価
  2. ラベル強化（擬似ラベル・スムージング・マルチソース統合）
  3. ノイズ耐性学習戦略
* 半教師あり学習は弱教師ありの特殊ケース（無ラベル問題）。
* 能動学習・半教師ありとの組み合わせで性能向上可能。

---

# <!-- fit -->📘 実践デモ

猫犬画像分類の事例で、弱教師あり学習を一通り実演。  
データはWebから収集した想定で、一定割合の誤ラベルを含む**不正確教師（Inaccurate Supervision）**の場面。

---

## 1. データ準備：弱ラベルの模擬

`torchvision.datasets.CIFAR10` を猫と犬のみ抽出して使用し、  
ラベルの20%をランダムに反転してノイズを付与。

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np

# 转换（缩放+张量化）
transform = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor()
])

# 加载 CIFAR-10
trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)

# 只保留猫(3)和狗(5)
def filter_cats_dogs(dataset):
    imgs, labels = [], []
    for img, label in dataset:
        if label in [3,5]:  # 3=cat, 5=dog
            imgs.append(img)
            labels.append(0 if label==3 else 1)  # cat=0, dog=1
    return torch.stack(imgs), torch.tensor(labels)

X_train, y_train = filter_cats_dogs(trainset)
X_test, y_test = filter_cats_dogs(testset)

# 制造20%噪声标签
noise_rate = 0.2
num_noisy = int(len(y_train) * noise_rate)
noise_idx = np.random.choice(len(y_train), num_noisy, replace=False)
y_train_noisy = y_train.clone()
y_train_noisy[noise_idx] = 1 - y_train_noisy[noise_idx]  # 标签反转

print(f"训练样本: {len(X_train)}, 含噪声样本: {num_noisy}")
```

---

## 2. データクリーニングと分析

実務では以下を含む場合がある：

* 簡易モデルやヒューリスティックで明らかな誤ラベルを除外
* 少量の人工ラベルでラベル精度を評価

このデモでは、ノイズを含んだまま学習し、耐性手法の効果に注目。

---

## 3. 弱教師学習：ノイズ耐性損失

ここでは **Bootstrap Loss** を使用し、ラベルとモデル予測を融合して誤ラベルの影響を軽減。

```python
from torch.utils.data import DataLoader, TensorDataset

# DataLoader
train_loader = DataLoader(TensorDataset(X_train, y_train_noisy.float()), batch_size=64, shuffle=True)
test_loader = DataLoader(TensorDataset(X_test, y_test.float()), batch_size=64)

# 简单CNN
class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64*16*16, 128), nn.ReLU(),
            nn.Linear(128, 1), nn.Sigmoid()
        )
    def forward(self, x):
        return self.classifier(self.features(x))

# Bootstrap Loss
class BootstrapLoss(nn.Module):
    def __init__(self, beta=0.8):
        super().__init__()
        self.beta = beta
        self.bce = nn.BCELoss()

    def forward(self, preds, labels):
        soft_labels = self.beta * labels + (1 - self.beta) * preds.detach()
        return self.bce(preds, soft_labels)

# 训练
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleCNN().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = BootstrapLoss(beta=0.8)

for epoch in range(5):
    model.train()
    total_loss = 0
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        preds = model(X_batch).squeeze()
        loss = criterion(preds, y_batch)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}")
```

---

## 4. モデル評価

```python
model.eval()
correct, total = 0, 0
with torch.no_grad():
    for X_batch, y_batch in test_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        preds = (model(X_batch).squeeze() > 0.5).float()
        correct += (preds == y_batch).sum().item()
        total += y_batch.size(0)
print(f"Test Accuracy: {correct/total:.4f}")
```

---

## 5. 改善案

実務での改善例：

1. **ラベルスムージング** → ハードラベル依存を緩和
2. **協調学習（Co-teaching）** → モデル同士がクリーンサンプルを選別
3. **半教師あり併用** → 高信頼度サンプルに擬似ラベル生成

